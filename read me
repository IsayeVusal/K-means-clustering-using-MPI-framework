# K-means-clustering-using-MPI-framework
Distributed K-means clustering using MPI framework

Mission of the k-means clustering is to take a given dataset and partition these observations up into k number of clusters. Deciding on where these clusters lie is computationally difficult but each cluster should be representative of all its surrounding data points. Algorithm is unsupervised learning method and hopes to gain some sort of insight into data that may be unseemingly unrelated.

Distributed Functionalities
Given that k-means clustering problem is a NP-Hard computationally intensive problem, a distributed approach seems appropriate. By dividing up the computation load among many worker nodes, the program can be parallelized and sped up.
The root node reads in the entire dataset and randomly chooses the initial k-means for each cluster.
The root node broadcasts the k-means to each n number of workers.
The root node distributes the dataset among n number of workers.
Given its portion of the entire dataset, each worker does computational work against each k-means cluster and returns the result to the root.
The algorithm repeats for X number of iterations.
